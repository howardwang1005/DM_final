{"cells":[{"cell_type":"markdown","metadata":{},"source":["Import lib."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import sys\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import random\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, train_test_split\n","from sklearn.metrics import f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix,accuracy_score,classification_report\n","import lightgbm as lgb\n","import xgboost as xgb\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn import svm\n","# from sklearn.datasets import load_files\n","# sys.path.append('..') \n","# import helpers.data_mining_helpers as dmh\n","\n","# import nltk\n","# nltk.download('punkt')\n","# import seaborn as sns\n","# from sklearn.decomposition import PCA\n","# from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n","# from sklearn.preprocessing import binarize\n","# from sklearn.metrics.pairwise import cosine_similarity\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Data input."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["train_file_path = 'training.csv'\n","test_file_path = 'public_processed.csv'\n","df = pd.read_csv(train_file_path)\n","testing_df = pd.read_csv(test_file_path)\n"]},{"cell_type":"markdown","metadata":{},"source":["df.shape : (8688526, 26)  |||  test_df.shape : (600182, 25)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# training_df = df.copy()\n","# test_df = testing_df.copy()\n","training_df = df\n","test_df = testing_df\n","y = training_df['label']\n","training_df = training_df.drop(['label','txkey'], axis=1)\n","test_df = test_df.drop(['txkey'], axis=1)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["train_num = training_df.shape[0]\n","test_num = test_df.shape[0]\n","allData = pd.concat([training_df ,test_df])\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["\n","# print(df.shape)\n","# print(test_df.shape)\n","\n","# Rename the columns to match the previous code\n","# df.columns = ['txkey', 'locdt', 'loctm', 'chid', 'cano', 'locdt']\n","# test_df.columns = ['sentence', 'score', 'provider']\n","\n","# Combine the two dataframes\n","# X = test_df\n","# display(test_df.head())\n","# display(df.head())\n","# Randomly select 3000 rows and drop duplicates and missing values\n","# X = X.sample(n=3000, random_state=42, replace=False)\n","# X.dropna(inplace=True)\n","# X.drop_duplicates(inplace=True)\n","# display(X)\n","\n","\n","label_encoder_chid = LabelEncoder()\n","label_encoder_cano = LabelEncoder()\n","label_encoder_mchno = LabelEncoder()\n","label_encoder_acqic = LabelEncoder()\n","label_encoder_etymd = LabelEncoder()\n","label_encoder_mcc = LabelEncoder()\n","label_encoder_stocn = LabelEncoder()\n","label_encoder_scity = LabelEncoder()\n","label_encoder_stscd = LabelEncoder()\n","label_encoder_hcefg = LabelEncoder()\n","label_encoder_csmcu = LabelEncoder()\n","\n","allData['chid'] = label_encoder_chid.fit_transform(allData['chid'])\n","allData['cano'] = label_encoder_cano.fit_transform(allData['cano'])\n","allData['mchno'] = label_encoder_mchno.fit_transform(allData['mchno'])\n","allData['acqic'] = label_encoder_acqic.fit_transform(allData['acqic'])\n","allData['etymd']= label_encoder_etymd.fit_transform(allData['etymd'])\n","allData['mcc']= label_encoder_mcc.fit_transform(allData['mcc'])\n","allData['stocn']= label_encoder_stocn.fit_transform(allData['stocn'])\n","allData['scity']= label_encoder_scity.fit_transform(allData['scity'])\n","allData['stscd']= label_encoder_stscd.fit_transform(allData['stscd'])\n","allData['hcefg']= label_encoder_hcefg.fit_transform(allData['hcefg'])\n","allData['csmcu']= label_encoder_csmcu.fit_transform(allData['csmcu'])\n","\n","# ##test\n","# test_df['chid'] = label_encoder.fit_transform(test_df['chid'])\n","# test_df['cano'] = label_encoder.fit_transform(test_df['cano'])\n","# test_df['mchno'] = label_encoder.fit_transform(test_df['mchno'])\n","# test_df['acqic'] = label_encoder.fit_transform(test_df['acqic'])\n","# test_df['etymd']= label_encoder.fit_transform(test_df['etymd'])\n","# test_df['mcc']= label_encoder.fit_transform(test_df['mcc'])\n","# test_df['stocn']= label_encoder.fit_transform(test_df['stocn'])\n","# test_df['scity']= label_encoder.fit_transform(test_df['scity'])\n","# test_df['stscd']= label_encoder.fit_transform(test_df['stscd'])\n","# test_df['hcefg']= label_encoder.fit_transform(test_df['hcefg'])\n","# test_df['csmcu']= label_encoder.fit_transform(test_df['csmcu'])\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["training_df = allData[:train_num]\n","test_df = allData[train_num:]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["0    70.0\n","1    70.0\n","2     NaN\n","3    70.0\n","4    68.0\n","Name: csmcu, dtype: float64"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["0    70.0\n","1    70.0\n","2     NaN\n","3    70.0\n","4    68.0\n","Name: csmcu, dtype: float64"]},"metadata":{},"output_type":"display_data"}],"source":["display(test_df['csmcu'].head())\n","display(testing_df['csmcu'].head())"]},{"cell_type":"markdown","metadata":{},"source":["Data preprocess."]},{"cell_type":"markdown","metadata":{},"source":["type:  \n","type0 : txkeys     \n","type1 (times) : locdt loctm        \n","type2 (money) : conam flam1 ovrlt csmcu csmam      \n","type3 (person) : chid cano     \n","type4 (places) : mchno stocn scity     \n","type5 (other trade types) : contp etymd acqic mcc ecfg insfg iterm bnsfg stscd flbmk hcefg flg_3dsmk       \n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","\n","\n","\n","fraud_df = training_df[df['label'] == 1]\n","non_fraud_df = training_df[df['label'] == 0]\n","# print(fraud_df.shape)\n","# print(non_fraud_df.shape)\n","# print(training_df.shape)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# each feature should use ifts own label encoder so that the unseen value can be handled\n","# try:\n","#     print(label_encoder.transform([-1]))\n","# except ValueError:\n","#     print(\"unseen value\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# training_df.drop(['txkey'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# print(fraud_df[col].shape[0]/ training_df[col].shape[0])\n","# print(non_fraud_df[col].shape[0]/ training_df[col].shape[0])\n","for col in training_df.columns:  \n","    print(f\"col: {col}\")\n","    # print(f\"nunique: {training_df[col].nunique()}\")\n","    # print(f\"unique values: {training_df[col].unique()}\")\n","    # print(f\"fraud nunique: {fraud_df[col].nunique()}\")\n","    # print(f\"fraud unique values: {fraud_df[col].unique()}\")\n","    # print(f\"non fraud nunique: {non_fraud_df[col].nunique()}\")\n","    # print(f\"non fraud unique values: {non_fraud_df[col].unique()}\")\n","    # print(fraud_df[col].nunique()/ training_df[col].nunique())\n","    # print(non_fraud_df[col].nunique()/ training_df[col].nunique()) \n","    unique_values = fraud_df[col].unique()\n","    # print(f\"unique values: {unique_values}\")\n","\n","    #average_ratio\n","    # average_ratio = 0\n","    # for value in unique_values:\n","    #     average_ratio += fraud_df[col][fraud_df[col] == value].shape[0]/ training_df[col][training_df[col] == value].shape[0]\n","    # average_ratio /= len(unique_values)\n","    # print(f\"average_ratio: {average_ratio}\")\n","\n","    #real_ratio\n","    # unique_values = fraud_df[col].unique()\n","    # numerator = np.sum(np.isin(fraud_df[col], unique_values))\n","    # denominator = np.sum(np.isin(training_df[col], unique_values))\n","    # average_ratio = numerator/denominator\n","    # print(f\"real_ratio: {average_ratio}\")\n","\n","    #max and min ratio top 10 and plot\n","    unique_values = fraud_df[col].unique()\n","    ratio_list = []\n","    for value in unique_values:\n","        ratio = fraud_df[col][fraud_df[col] == value].shape[0]/ training_df[col][training_df[col] == value].shape[0]\n","        ratio_list.append(ratio)\n","    ratio_list.sort(reverse=True)\n","    if len(ratio_list) > 10:\n","        print(f\"max ratio top 10: {ratio_list[:10]}\")\n","        plt.figure(figsize=(10, 5))\n","        plt.bar(np.arange(1, 11), ratio_list[:10])\n","        plt.title(f\"Max Ratio of Fraud Transactions for {col}\")\n","        plt.xlabel(\"Unique Values\")\n","        plt.ylabel(\"Max Ratio of Fraud Transactions\")\n","        plt.show()\n","        print(f\"min ratio top 10: {ratio_list[-10:]}\")\n","        plt.figure(figsize=(10, 5))\n","        plt.bar(np.arange(1, 11), ratio_list[-10:])\n","        plt.title(f\"Min Ratio of Fraud Transactions for {col}\")\n","        plt.xlabel(\"Unique Values\")\n","        plt.ylabel(\"Min Ratio of Fraud Transactions\")\n","        plt.show()\n","    else:\n","        print(f\"max ratio: {ratio_list}\")\n","        plt.figure(figsize=(10, 5))\n","        plt.bar(unique_values, ratio_list)\n","        plt.title(f\"Max Ratio of Fraud Transactions for {col}\")\n","        plt.xlabel(\"Unique Values\")\n","        plt.ylabel(\"Max Ratio of Fraud Transactions\")\n","        plt.show()\n","    print('\\n')\n"]},{"cell_type":"markdown","metadata":{},"source":["Average ratio:  all unique value in fraud_df and average (amount in fraud_df / amount in training_df) for each feature(column)   \n","col: label      \n","\n","---\n","col: cano       \n","col: chid       \n","col: scity      \n","col: mchno      \n","col: conam      \n","\n","---\n","col: acqic      \n","col: stocn      \n","col: csmcu       \n","col: stscd      \n","col: flam1      \n","col: hcefg      \n","col: mcc        \n","\n","---\n","col: csmam      \n","col: loctm      \n","\n","---\n","col: locdt      \n","col: contp      \n","col: etymd      \n","col: ecfg       \n","col: insfg     \n","col: iterm      \n","col: bnsfg     \n","col: ovrlt   \n","col: flbmk   \n","col: flg_3dsmk "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# y = training_df['label']\n","# X = training_df.drop(['label','txkey'], axis=1)\n","X = training_df\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["training & testing."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/swc/DM_Final/lib/python3.8/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Number of positive: 25694, number of negative: 6925126\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.249080 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 39625\n","[LightGBM] [Info] Number of data points in the train set: 6950820, number of used features: 24\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003697 -> initscore=-5.596654\n","[LightGBM] [Info] Start training from score -5.596654\n"]}],"source":["\n","\n","\n","# df_sample = df.sample(n=300000, random_state=42)\n","# train_df, val_df = train_test_split(df_sample, test_size=0.2, random_state=42)\n","\n","# # Define the features and target variable\n","# #featues 前面preprocess先做好這邊在註解掉\n","# features = [ 'locdt','loctm','contp','etymd','mcc','conam','ecfg','insfg','iterm','bnsfg','flam1','stocn','scity','ovrlt','flbmk','hcefg','csmcu','csmam','flg_3dsmk'] \n","# target = 'label'\n","\n","# # Split the training and validation datasets into features and target variable\n","# X_train = train_df[features]\n","# y_train = train_df[target]\n","# X_val = val_df[features]\n","# y_val = val_df[target]\n","\n","# # Train the model using LightGBM\n","\n","# # params = {\n","# #     'objective': 'binary',\n","# #     'metric': 'binary_logloss',\n","# #     'boosting_type': 'dart',\n","# #     'num_leaves': 50,  \n","# #     'learning_rate': 0.01,  \n","# #     'feature_fraction': 0.8  \n","# # }\n","# params = {'objective': 'binary',\n","#           'boosting_type': 'gbdt',\n","#           'metric': 'auc',\n","#           'learning_rate': 0.007,\n","#           'num_leaves': 2**8,\n","#           'max_depth': -1,\n","#           'tree_learner':'serial',\n","#           'colsample_bytree': 0.5,\n","#           'subsample_freq':1,\n","#           'subsample':0.7,\n","#           'n_estimators':10000,\n","#           'min_data_in_leaf': 106,\n","#           'max_bin':255,\n","#           'verbosity': -1,\n","#           'early_stopping_rounds':100,\n","#          }\n","\n","\n","# train_data = lgb.Dataset(X_train, label=y_train)\n","# val_data = lgb.Dataset(X_val, label=y_val)\n","\n","# model = lgb.train(params, train_data, num_boost_round=10000, valid_sets=[train_data, val_data])\n","# model = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[train_data, val_data], early_stopping_rounds=50)\n","\n","categories = ['chid', 'cano', 'contp', 'etymd', 'mchno', 'acqic',\n","              'mcc',  'ecfg', 'insfg',  'bnsfg', 'stocn', 'scity',\n","              'stscd', 'ovrlt', 'flbmk', 'hcefg', 'csmcu', 'flg_3dsmk']\n","\n","params = {\n","    'objective': 'binary',\n","    'metric': 'cross_entropy',\n","    'num_leaves': 31,\n","    'learning_rate': 0.005,\n","    'n_estimators': 3000,\n","    'boosting_type': 'gbdt',\n","}   \n","\n","train_data = lgb.Dataset(X_train, label=y_train,\n","                         categorical_feature=categories)\n","test_data = lgb.Dataset(X_test, label=y_test,\n","                        reference=train_data)\n","\n","bst = lgb.train(params, train_data,num_boost_round = 100,  valid_sets=[test_data],categorical_feature=categories)"]},{"cell_type":"markdown","metadata":{},"source":["validation."]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9979213975206392\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00   1731371\n","           1       0.83      0.54      0.65      6335\n","\n","    accuracy                           1.00   1737706\n","   macro avg       0.92      0.77      0.83   1737706\n","weighted avg       1.00      1.00      1.00   1737706\n","\n"]}],"source":["y_pred_prob = bst.predict(X_test, num_iteration=bst.best_iteration)\n","y_pred = [1 if x >= 0.5 else 0 for x in y_pred_prob]  # Assuming binary classification, adjust as needed\n","# y_pred = model.predict(X_val)\n","# print(y_pred)\n","# # Get the true labels from the validation set\n","# y_true = val_data.label\n","\n","# # Calculate F1 score\n","# f1 = f1_score(y_val, y_pred)\n","# print(f'F1 Score on Validation Set: {f1}')\n","\n","# y_pred = pd.Series(bst.predict(X_test, num_iteration=bst.best_iteration)>0.5).astype(int)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["predict."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# display(training_df.head())\n","# display(X_test.head())\n","# display(test_df.head())\n","# predict_data = test_df.drop(['txkey'], axis=1)\n","predict_data = test_df\n","y_pred = pd.Series(bst.predict(predict_data, num_iteration=bst.best_iteration)>0.5).astype(int)\n","# pridict = pd.DataFrame(test_df['txkey'] )\n","# pridict['pred'] = y_pred # put here\n","# display(pridict)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>txkey</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a2c1209018e4e52e04f6fabb48f05f1b8bc09dc838ff6c...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>16c4880500059e01553789be11bbb50753b7acaae7b95b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>623c56be3bee87724e3d119c271d9ed098eeda84233183...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>250da12187059cf6e3a3066656a2919d08ceb8207efd55...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4b268e0da036f44cbbb056ddfac6a28ea336d9cf299843...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>600177</th>\n","      <td>741a391b2c2114491d1d18acb1a892341b9280e1e3529f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600178</th>\n","      <td>76f613595631fb35938bf10f5b7abe3f60a3d34ccf5f44...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600179</th>\n","      <td>c32e846a4469e4869e2df8f8e160fba4e829b6beebb44d...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600180</th>\n","      <td>d641cd25a830de759cd55b4a643d71eadb770bc917aed3...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600181</th>\n","      <td>301d0262bdd594a886446ddca09b4a21bef51dddf9618a...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>600182 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    txkey  pred\n","0       a2c1209018e4e52e04f6fabb48f05f1b8bc09dc838ff6c...     0\n","1       16c4880500059e01553789be11bbb50753b7acaae7b95b...     0\n","2       623c56be3bee87724e3d119c271d9ed098eeda84233183...     0\n","3       250da12187059cf6e3a3066656a2919d08ceb8207efd55...     0\n","4       4b268e0da036f44cbbb056ddfac6a28ea336d9cf299843...     0\n","...                                                   ...   ...\n","600177  741a391b2c2114491d1d18acb1a892341b9280e1e3529f...     0\n","600178  76f613595631fb35938bf10f5b7abe3f60a3d34ccf5f44...     0\n","600179  c32e846a4469e4869e2df8f8e160fba4e829b6beebb44d...     0\n","600180  d641cd25a830de759cd55b4a643d71eadb770bc917aed3...     0\n","600181  301d0262bdd594a886446ddca09b4a21bef51dddf9618a...     0\n","\n","[600182 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# test_df = pd.read_csv(test_file_path)\n","pridict = pd.DataFrame(testing_df['txkey'] )\n","pridict['pred'] = y_pred \n","# display(y_pred )\n","# print(np.nonzero(y_pred))\n","# print(y_pred[1771])\n","# display(pridict.iloc[1900])\n","display(pridict)"]},{"cell_type":"markdown","metadata":{},"source":["output."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["pridict.to_csv('output.csv', index=False)"]}],"metadata":{"colab":{"collapsed_sections":["PQPCUbx1ie4R","8qg4up1B_EhD","lC7ymUlG_fai","xtvWLH1x_7nV","bgULadKFBXL-","SZ4rgA1mBir5","9VirxMl6CGN2","yoTS9Vh8ESzB","NGVM3wSjFt7v","bH9BQLSWF9Uf","y8I6L8Z8JGsv","TFIl1hpMJqnv","DobYRQ4FLetu","9pfemrkcLiUG"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}

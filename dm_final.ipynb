{"cells":[{"cell_type":"markdown","metadata":{},"source":["Import lib."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import sys\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import random\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, train_test_split\n","from sklearn.metrics import f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n","import lightgbm as lgb\n","import xgboost as xgb\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn import svm\n","# from sklearn.datasets import load_files\n","# sys.path.append('..') \n","# import helpers.data_mining_helpers as dmh\n","\n","# import nltk\n","# nltk.download('punkt')\n","# import seaborn as sns\n","# from sklearn.decomposition import PCA\n","# from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n","# from sklearn.preprocessing import binarize\n","# from sklearn.metrics.pairwise import cosine_similarity\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Data input."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["train_file_path = 'training.csv'\n","test_file_path = 'public_processed.csv'\n","df = pd.read_csv(train_file_path)\n","test_df = pd.read_csv(test_file_path)\n"]},{"cell_type":"markdown","metadata":{},"source":["df.shape : (8688526, 26)  |||  test_df.shape : (600182, 25)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["training_df = df\n","# print(df.shape)\n","# print(test_df.shape)\n","\n","# Rename the columns to match the previous code\n","# df.columns = ['txkey', 'locdt', 'loctm', 'chid', 'cano', 'locdt']\n","# test_df.columns = ['sentence', 'score', 'provider']\n","\n","# Combine the two dataframes\n","# X = test_df\n","# display(test_df.head())\n","# display(df.head())\n","# Randomly select 3000 rows and drop duplicates and missing values\n","# X = X.sample(n=3000, random_state=42, replace=False)\n","# X.dropna(inplace=True)\n","# X.drop_duplicates(inplace=True)\n","# display(X)\n","\n","\n","\n","\n","label_encoder = LabelEncoder()\n","training_df['chid'] = label_encoder.fit_transform(training_df['chid'])\n","training_df['cano'] = label_encoder.fit_transform(training_df['cano'])\n","training_df['mchno'] = label_encoder.fit_transform(training_df['mchno'])\n","training_df['acqic'] = label_encoder.fit_transform(training_df['acqic'])\n","training_df['etymd']= label_encoder.fit_transform(training_df['etymd'])\n","training_df['mcc']= label_encoder.fit_transform(training_df['mcc'])\n","training_df['stocn']= label_encoder.fit_transform(training_df['stocn'])\n","training_df['scity']= label_encoder.fit_transform(training_df['scity'])\n","training_df['stscd']= label_encoder.fit_transform(training_df['stscd'])\n","training_df['hcefg']= label_encoder.fit_transform(training_df['hcefg'])\n","training_df['csmcu']= label_encoder.fit_transform(training_df['csmcu'])\n","##test\n","test_df['chid'] = label_encoder.fit_transform(test_df['chid'])\n","test_df['cano'] = label_encoder.fit_transform(test_df['cano'])\n","test_df['mchno'] = label_encoder.fit_transform(test_df['mchno'])\n","test_df['acqic'] = label_encoder.fit_transform(test_df['acqic'])\n","test_df['etymd']= label_encoder.fit_transform(test_df['etymd'])\n","test_df['mcc']= label_encoder.fit_transform(test_df['mcc'])\n","test_df['stocn']= label_encoder.fit_transform(test_df['stocn'])\n","test_df['scity']= label_encoder.fit_transform(test_df['scity'])\n","test_df['stscd']= label_encoder.fit_transform(test_df['stscd'])\n","test_df['hcefg']= label_encoder.fit_transform(test_df['hcefg'])\n","test_df['csmcu']= label_encoder.fit_transform(test_df['csmcu'])\n"]},{"cell_type":"markdown","metadata":{},"source":["Data preprocess."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["y = training_df['label']\n","X = training_df.drop(['label','txkey'], axis=1)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["training & testing."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\lo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","c:\\Users\\lo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n","Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n","  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n","c:\\Users\\lo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n","  _log_warning(f'{cat_alias} in param dict is overridden.')\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Warning] categorical_feature is set=chid,cano,contp,etymd,mchno,acqic,mcc,ecfg,insfg,bnsfg,stocn,scity,stscd,ovrlt,flbmk,hcefg,csmcu,flg_3dsmk, categorical_column=2,3,4,5,6,7,8,10,11,13,15,16,17,18,19,20,21,23 will be ignored. Current value: categorical_feature=chid,cano,contp,etymd,mchno,acqic,mcc,ecfg,insfg,bnsfg,stocn,scity,stscd,ovrlt,flbmk,hcefg,csmcu,flg_3dsmk\n","[LightGBM] [Info] Number of positive: 25694, number of negative: 6925126\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 39625\n","[LightGBM] [Info] Number of data points in the train set: 6950820, number of used features: 24\n"]},{"ename":"LightGBMError","evalue":"bin size 15964 cannot run on GPU","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)","\u001b[1;32md:\\4up\\DM\\Final\\dataset_1st\\dm_final.ipynb Cell 11\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/4up/DM/Final/dataset_1st/dm_final.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m train_data \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_train, label\u001b[39m=\u001b[39my_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/4up/DM/Final/dataset_1st/dm_final.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                          categorical_feature\u001b[39m=\u001b[39mcategories)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/4up/DM/Final/dataset_1st/dm_final.ipynb#X12sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m test_data \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_test, label\u001b[39m=\u001b[39my_test,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/4up/DM/Final/dataset_1st/dm_final.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m                         reference\u001b[39m=\u001b[39mtrain_data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/4up/DM/Final/dataset_1st/dm_final.ipynb#X12sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m bst \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(params, train_data,  valid_sets\u001b[39m=\u001b[39;49m[test_data])\n","File \u001b[1;32mc:\\Users\\lo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:255\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    257\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n","File \u001b[1;32mc:\\Users\\lo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\basic.py:3204\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3202\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n\u001b[0;32m   3203\u001b[0m params_str \u001b[39m=\u001b[39m _param_dict_to_str(params)\n\u001b[1;32m-> 3204\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterCreate(\n\u001b[0;32m   3205\u001b[0m     train_set\u001b[39m.\u001b[39;49m_handle,\n\u001b[0;32m   3206\u001b[0m     _c_str(params_str),\n\u001b[0;32m   3207\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle)))\n\u001b[0;32m   3208\u001b[0m \u001b[39m# save reference to data\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_set \u001b[39m=\u001b[39m train_set\n","File \u001b[1;32mc:\\Users\\lo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\basic.py:242\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \n\u001b[0;32m    236\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 242\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n","\u001b[1;31mLightGBMError\u001b[0m: bin size 15964 cannot run on GPU"]}],"source":["\n","\n","\n","# df_sample = df.sample(n=300000, random_state=42)\n","# train_df, val_df = train_test_split(df_sample, test_size=0.2, random_state=42)\n","\n","# # Define the features and target variable\n","# #featues 前面preprocess先做好這邊在註解掉\n","# features = [ 'locdt','loctm','contp','etymd','mcc','conam','ecfg','insfg','iterm','bnsfg','flam1','stocn','scity','ovrlt','flbmk','hcefg','csmcu','csmam','flg_3dsmk'] \n","# target = 'label'\n","\n","# # Split the training and validation datasets into features and target variable\n","# X_train = train_df[features]\n","# y_train = train_df[target]\n","# X_val = val_df[features]\n","# y_val = val_df[target]\n","\n","# # Train the model using LightGBM\n","\n","# # params = {\n","# #     'objective': 'binary',\n","# #     'metric': 'binary_logloss',\n","# #     'boosting_type': 'dart',\n","# #     'num_leaves': 50,  \n","# #     'learning_rate': 0.01,  \n","# #     'feature_fraction': 0.8  \n","# # }\n","# params = {'objective': 'binary',\n","#           'boosting_type': 'gbdt',\n","#           'metric': 'auc',\n","#           'learning_rate': 0.007,\n","#           'num_leaves': 2**8,\n","#           'max_depth': -1,\n","#           'tree_learner':'serial',\n","#           'colsample_bytree': 0.5,\n","#           'subsample_freq':1,\n","#           'subsample':0.7,\n","#           'n_estimators':10000,\n","#           'min_data_in_leaf': 106,\n","#           'max_bin':255,\n","#           'verbosity': -1,\n","#           'early_stopping_rounds':100,\n","#          }\n","\n","\n","# train_data = lgb.Dataset(X_train, label=y_train)\n","# val_data = lgb.Dataset(X_val, label=y_val)\n","\n","# model = lgb.train(params, train_data, num_boost_round=10000, valid_sets=[train_data, val_data])\n","# model = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[train_data, val_data], early_stopping_rounds=50)\n","\n","categories = ['chid', 'cano', 'contp', 'etymd', 'mchno', 'acqic',\n","              'mcc',  'ecfg', 'insfg',  'bnsfg', 'stocn', 'scity',\n","              'stscd', 'ovrlt', 'flbmk', 'hcefg', 'csmcu', 'flg_3dsmk']\n","\n","params = {\n","    'objective': 'binary',\n","    'metric': 'auc',\n","    'num_leaves': 31,\n","    'learning_rate': 0.005,\n","    'n_estimators': 3000,\n","    'boosting_type': 'gbdt',\n","    'categorical_feature': categories,\n","}   \n","\n","train_data = lgb.Dataset(X_train, label=y_train,\n","                         categorical_feature=categories)\n","test_data = lgb.Dataset(X_test, label=y_test,\n","                        reference=train_data)\n","\n","bst = lgb.train(params, train_data,  valid_sets=[test_data])"]},{"cell_type":"markdown","metadata":{},"source":["validation."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 Score on Validation Set: 0.0\n"]}],"source":["# y_pred_prob = model.predict(X_val)\n","# y_pred = [1 if x >= 0.5 else 0 for x in y_pred_prob]  # Assuming binary classification, adjust as needed\n","# # y_pred = model.predict(X_val)\n","# # print(y_pred)\n","# # # Get the true labels from the validation set\n","# # y_true = val_data.label\n","\n","# # # Calculate F1 score\n","# f1 = f1_score(y_val, y_pred)\n","# print(f'F1 Score on Validation Set: {f1}')\n","\n","# y_pred = pd.Series(bst.predict(X_test, num_iteration=bst.best_iteration)>0.5).astype(int)\n","\n","# accuracy = accuracy_score(y_test, y_pred)\n","# print(\"Accuracy:\", accuracy)\n","# print(\"Classification Report:\")\n","# print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["predict."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# display(training_df.head())\n","# display(X_test.head())\n","# display(test_df.head())\n","predict_data = test_df.drop(['txkey'], axis=1)\n","y_pred = pd.Series(bst.predict(predict_data, num_iteration=bst.best_iteration)>0.5).astype(int)\n","# pridict = pd.DataFrame(test_df['txkey'] )\n","# pridict['pred'] = y_pred # put here\n","# display(pridict)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>txkey</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a2c1209018e4e52e04f6fabb48f05f1b8bc09dc838ff6c...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>16c4880500059e01553789be11bbb50753b7acaae7b95b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>623c56be3bee87724e3d119c271d9ed098eeda84233183...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>250da12187059cf6e3a3066656a2919d08ceb8207efd55...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4b268e0da036f44cbbb056ddfac6a28ea336d9cf299843...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>600177</th>\n","      <td>741a391b2c2114491d1d18acb1a892341b9280e1e3529f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600178</th>\n","      <td>76f613595631fb35938bf10f5b7abe3f60a3d34ccf5f44...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600179</th>\n","      <td>c32e846a4469e4869e2df8f8e160fba4e829b6beebb44d...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600180</th>\n","      <td>d641cd25a830de759cd55b4a643d71eadb770bc917aed3...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>600181</th>\n","      <td>301d0262bdd594a886446ddca09b4a21bef51dddf9618a...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>600182 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    txkey  pred\n","0       a2c1209018e4e52e04f6fabb48f05f1b8bc09dc838ff6c...     0\n","1       16c4880500059e01553789be11bbb50753b7acaae7b95b...     0\n","2       623c56be3bee87724e3d119c271d9ed098eeda84233183...     0\n","3       250da12187059cf6e3a3066656a2919d08ceb8207efd55...     0\n","4       4b268e0da036f44cbbb056ddfac6a28ea336d9cf299843...     0\n","...                                                   ...   ...\n","600177  741a391b2c2114491d1d18acb1a892341b9280e1e3529f...     0\n","600178  76f613595631fb35938bf10f5b7abe3f60a3d34ccf5f44...     0\n","600179  c32e846a4469e4869e2df8f8e160fba4e829b6beebb44d...     0\n","600180  d641cd25a830de759cd55b4a643d71eadb770bc917aed3...     0\n","600181  301d0262bdd594a886446ddca09b4a21bef51dddf9618a...     0\n","\n","[600182 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# test_df = pd.read_csv(test_file_path)\n","pridict = pd.DataFrame(test_df['txkey'] )\n","pridict['pred'] = y_pred \n","# display(y_pred )\n","# print(np.nonzero(y_pred))\n","# print(y_pred[1771])\n","# display(pridict.iloc[1900])\n","display(pridict)"]},{"cell_type":"markdown","metadata":{},"source":["output."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["pridict.to_csv('output.csv', index=False)"]}],"metadata":{"colab":{"collapsed_sections":["PQPCUbx1ie4R","8qg4up1B_EhD","lC7ymUlG_fai","xtvWLH1x_7nV","bgULadKFBXL-","SZ4rgA1mBir5","9VirxMl6CGN2","yoTS9Vh8ESzB","NGVM3wSjFt7v","bH9BQLSWF9Uf","y8I6L8Z8JGsv","TFIl1hpMJqnv","DobYRQ4FLetu","9pfemrkcLiUG"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
